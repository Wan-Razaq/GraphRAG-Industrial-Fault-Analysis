{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function to clean \" | \" formatting ---\n",
    "def clean_pipe_spacing(text):\n",
    "    if not isinstance(text, str):\n",
    "        return text\n",
    "    return re.sub(r'\\s*[\\.,;:!?]*\\s*\\|\\s*[\\.,;:!?]*\\s*', ' | ', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Function to load and clean CSV into a DataFrame ---\n",
    "def load_and_clean_csv(filepath):\n",
    "    cleaned_rows = []\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        reader = csv.reader(f, delimiter=';', quotechar='\"')\n",
    "        headers = next(reader)\n",
    "\n",
    "        for row in reader:\n",
    "            cleaned_row = [\n",
    "                cell.replace('\\n', ' | ').replace('\\r', ' | ').replace('\\t', '') if cell else cell\n",
    "                for cell in row\n",
    "            ]\n",
    "            cleaned_rows.append(cleaned_row)\n",
    "\n",
    "    return pd.DataFrame(cleaned_rows, columns=headers[:len(cleaned_rows[0])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load both IBM3 and IBM4 ---\n",
    "df_ibm3 = load_and_clean_csv(\"IBM3_Only_Preprocessed.csv\")\n",
    "df_ibm4 = load_and_clean_csv(\"IBM4_Only_Preprocessed.csv\")\n",
    "\n",
    "# --- Combine both datasets ---\n",
    "df_combined = pd.concat([df_ibm3, df_ibm4], ignore_index=True)\n",
    "\n",
    "# --- Group by Case-ID and aggregate fields ---\n",
    "grouped = df_combined.groupby(\"Case-ID\").agg({\n",
    "    \"Issues\": lambda x: \"\\n- \" + \"\\n- \".join(clean_pipe_spacing(i) for i in x.dropna().astype(str)),\n",
    "    \"Source\": lambda x: \", \".join(set(x.dropna().astype(str))),\n",
    "    \"Resolution_status\": lambda x: \", \".join(set(x.dropna().astype(str)))\n",
    "}).reset_index()\n",
    "\n",
    "# --- Format final text for Doccano ---\n",
    "grouped[\"text\"] = grouped.apply(\n",
    "    lambda row: clean_pipe_spacing(\n",
    "        f\"Case-ID: {row['Case-ID']}\\nSources: {row['Source']}\\nIssues:{row['Issues']}\\nResolution Status: {row['Resolution_status']}\"\n",
    "    ),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Prepare for Doccano import ---\n",
    "doccano_ready = grouped[[\"text\"]].copy()\n",
    "doccano_ready[\"label\"] = [[]] * len(doccano_ready)\n",
    "\n",
    "# --- Export to JSONL ---\n",
    "doccano_ready.to_json(\"doccano_ibm3_ibm4_grouped_ready.jsonl\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Combined Doccano file saved as: doccano_ibm3_ibm4_grouped_ready.jsonl\n",
      "Total grouped cases: 186\n",
      "Unique Case-IDs in combined data: 186\n"
     ]
    }
   ],
   "source": [
    "# --- Stats ---\n",
    "print(\" Combined Doccano file saved as: doccano_ibm3_ibm4_grouped_ready.jsonl\")\n",
    "print(\"Total grouped cases:\", doccano_ready.shape[0])\n",
    "print(\"Unique Case-IDs in combined data:\", df_combined[\"Case-ID\"].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❗ Missing case(s): set()\n",
      "✅ Exported 20 cases for few-shot prompting to: 20_cases_for_baml_fewshot.jsonl\n"
     ]
    }
   ],
   "source": [
    "# --- List of selected 20 case IDs for few-shot prompting ---\n",
    "\n",
    "import json\n",
    "\n",
    "selected_case_ids = [\n",
    "    \"IBM3_C4_16-Oct-13_16-Oct-13\",\n",
    "    \"IBM3_C26_21-Sep-16_22-Sep-16\",\n",
    "    \"IBM3_C29_05-Jul-17_12-Jul-17\",\n",
    "    \"IBM3_C38_18-Nov-19_18-Nov-19\",\n",
    "    \"IBM3_C45_26-Oct-20_26-Oct-20\",\n",
    "    \"IBM3_C46_26-Oct-20_26-Oct-20\",\n",
    "    \"IBM3_C53_31-Mar-21_31-Mar-21\",\n",
    "    \"IBM3_C55_10-Aug-21_10-Aug-21\",\n",
    "    \"IBM3_C60_29_Mar_22-15-Apr-22\",\n",
    "    \"IBM3_C74_12-Sep-23_12-Sep-23\",\n",
    "    \"IBM3_C9_28-Jul-14_28-Jul-14\",\n",
    "    \"IBM4_C37_25-Jun-18_25-Jun-18\",\n",
    "    \"IBM4_C59_05-Aug-21_05-Aug-21\",\n",
    "    \"IBM4_C62_23-Dec-21_23-Dec-21\",\n",
    "    \"IBM4_C74_01-Dec-22_01-Dec-22\",\n",
    "    \"IBM4_C77_18-Mar-23_19-Apr-23\",\n",
    "    \"IBM4_C79_13-Jun-23_13-Jun-23\",\n",
    "    \"IBM4_C91_23-Sept-24_01-Oct-24\",\n",
    "    \"IBM3_C15_23-Feb-15_23-Feb-15\",\n",
    "    \"IBM4_C31_27-Mar-17_27-Mar-17\"\n",
    "]\n",
    "\n",
    "# Filter the grouped DataFrame\n",
    "selected_for_prompting = grouped[grouped[\"Case-ID\"].isin(selected_case_ids)].copy()\n",
    "\n",
    "# Print which case IDs were not found\n",
    "missing = set(selected_case_ids) - set(selected_for_prompting[\"Case-ID\"].tolist())\n",
    "print(\" Missing case(s):\", missing)\n",
    "\n",
    "# Save directly as plain string objects in JSONL (not as dict with keys)\n",
    "with open(\"20_cases_for_baml_fewshot.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in selected_for_prompting.iterrows():\n",
    "        json.dump(row[\"text\"], f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(\" Exported 20 cases for few-shot prompting to: 20_cases_for_baml_fewshot.jsonl\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported remaining cases to: remaining_cases_for_baml_fewshot.jsonl\n",
      "Total remaining cases: 87\n",
      "Excluded evaluation cases: 20\n",
      "Excluded few-shot example cases: 5\n"
     ]
    }
   ],
   "source": [
    "# Preparing the remaining cases for few-shot prompting\n",
    "\n",
    "# --- IDs explicitly excluded (20 evaluation cases) ---\n",
    "excluded_evaluation_ids = {\n",
    "    \"IBM3_C4_16-Oct-13_16-Oct-13\",\n",
    "    \"IBM3_C26_21-Sep-16_22-Sep-16\",\n",
    "    \"IBM3_C29_05-Jul-17_12-Jul-17\",\n",
    "    \"IBM3_C38_18-Nov-19_18-Nov-19\",\n",
    "    \"IBM3_C45_26-Oct-20_26-Oct-20\",\n",
    "    \"IBM3_C46_26-Oct-20_26-Oct-20\",\n",
    "    \"IBM3_C53_31-Mar-21_31-Mar-21\",\n",
    "    \"IBM3_C55_10-Aug-21_10-Aug-21\",\n",
    "    \"IBM3_C60_29_Mar_22-15-Apr-22\",\n",
    "    \"IBM3_C74_12-Sep-23_12-Sep-23\",\n",
    "    \"IBM3_C9_28-Jul-14_28-Jul-14\",\n",
    "    \"IBM4_C37_25-Jun-18_25-Jun-18\",\n",
    "    \"IBM4_C59_05-Aug-21_05-Aug-21\",\n",
    "    \"IBM4_C62_23-Dec-21_23-Dec-21\",\n",
    "    \"IBM4_C74_01-Dec-22_01-Dec-22\",\n",
    "    \"IBM4_C77_18-Mar-23_19-Apr-23\",\n",
    "    \"IBM4_C79_13-Jun-23_13-Jun-23\",\n",
    "    \"IBM4_C91_23-Sept-24_01-Oct-24\",\n",
    "    \"IBM3_C15_23-Feb-15_23-Feb-15\",\n",
    "    \"IBM4_C31_27-Mar-17_27-Mar-17\"\n",
    "}\n",
    "\n",
    "# --- ALSO exclude the 5 few-shot examples used (recommended) ---\n",
    "excluded_fewshot_example_ids = {\n",
    "    \"IBM3_C21_19-Jul-16_01-Aug-16\",\n",
    "    \"IBM3_C22_03-Aug-16_04-Aug-16\",\n",
    "    \"IBM4_C29_06-Dec-16_06-Dec-16\",\n",
    "    \"IBM4_C41_04-Jul-18_04-Jul-18\",\n",
    "    \"IBM4_C51_03-Jul-20_03-Jul-20\"\n",
    "}\n",
    "\n",
    "# Combine both sets\n",
    "all_excluded_ids = excluded_evaluation_ids | excluded_fewshot_example_ids\n",
    "\n",
    "# --- Filter out excluded cases ---\n",
    "remaining_cases = grouped[~grouped[\"Case-ID\"].isin(all_excluded_ids)].copy()\n",
    "\n",
    "# --- Filter to only include cases with 'resolved' or 'unknown' resolution status ---\n",
    "remaining_cases = grouped[\n",
    "    (~grouped[\"Case-ID\"].isin(all_excluded_ids)) &\n",
    "    (grouped[\"Resolution_status\"].str.strip().str.lower().isin([\"resolved\", \"unknown\"]))\n",
    "].copy()\n",
    "\n",
    "# --- Export remaining cases to a new file ---\n",
    "output_filename = \"remaining_cases_for_baml_fewshot.jsonl\"\n",
    "with open(output_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in remaining_cases.iterrows():\n",
    "        json.dump(row[\"text\"], f, ensure_ascii=False)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(f\"Exported remaining cases to: {output_filename}\")\n",
    "print(f\"Total remaining cases: {len(remaining_cases)}\")\n",
    "print(f\"Excluded evaluation cases: {len(excluded_evaluation_ids)}\")\n",
    "print(f\"Excluded few-shot example cases: {len(excluded_fewshot_example_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
